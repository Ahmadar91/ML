{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "import scipy.io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import glob\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 227, 227])\n",
      "tensor([2, 1, 2, 0, 1, 0, 2, 0, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 100  # or another appropriate value based on your data\n",
    "\n",
    "\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, mat_files, transform=None):\n",
    "        self.mat_files = mat_files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mat_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.mat_files[idx], \"r\") as f:\n",
    "            image = f[\"cjdata\"][\"image\"][()]\n",
    "\n",
    "            label = int(\n",
    "                f[\"cjdata\"][\"label\"][0][0] - 1\n",
    "            )  # Convert labels from 1-3 to 0-2\n",
    "\n",
    "            # Convert to grayscale ('L' mode) before applying transformations\n",
    "            image = Image.fromarray(image).convert(\"L\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Sample use:\n",
    "# Assuming path to .mat files is './data/New folder/'\n",
    "mat_files = [\n",
    "    os.path.join(\"./data/New folder/\", f)\n",
    "    for f in os.listdir(\"./data/New folder/\")\n",
    "    if f.endswith(\".mat\")\n",
    "]\n",
    "\n",
    "# Split the data into train and test sets (e.g., 80% train, 20% test)\n",
    "indices = list(range(len(mat_files)))\n",
    "split = int(np.floor(0.7 * len(mat_files)))\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[:split], indices[split:]\n",
    "\n",
    "\n",
    "# Transforms\n",
    "transforming_img = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((227, 227)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_set = Subset(\n",
    "    BrainTumorDataset(mat_files, transform=transforming_img), train_indices\n",
    ")\n",
    "test_set = Subset(\n",
    "    BrainTumorDataset(mat_files, transform=transforming_img), test_indices\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=10, shuffle=False)\n",
    "\n",
    "# Sample training loop:\n",
    "for image, label in train_loader:\n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.562102735042572\n",
      "Standard Deviation: 0.42450031638145447\n"
     ]
    }
   ],
   "source": [
    "# Initializing variables to store sum and squared sum\n",
    "total_sum = 0\n",
    "total_squared_sum = 0\n",
    "num_pixels = 0\n",
    "\n",
    "# Calculating mean and standard deviation\n",
    "for data, _ in train_set:\n",
    "    total_sum += data.sum()\n",
    "    total_squared_sum += (data**2).sum()\n",
    "    num_pixels += data.numel()\n",
    "\n",
    "mean = total_sum / num_pixels\n",
    "std_dev = (total_squared_sum / num_pixels - mean**2) ** 0.5\n",
    "\n",
    "print(f\"Mean: {mean.item()}\")\n",
    "print(f\"Standard Deviation: {std_dev.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 227, 227])\n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Transforms\n",
    "transforming_img = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((227, 227)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((mean.item()), (std_dev.item())),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_set = Subset(\n",
    "    BrainTumorDataset(mat_files, transform=transforming_img), train_indices\n",
    ")\n",
    "test_set = Subset(\n",
    "    BrainTumorDataset(mat_files, transform=transforming_img), test_indices\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=10, shuffle=False)\n",
    "\n",
    "# Sample training loop:\n",
    "for image, label in train_loader:\n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AdjustedFashionCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=28,\n",
    "        kernel_size=5,\n",
    "        num_filters1=32,\n",
    "        num_filters2=64,\n",
    "        dropout_rate=0.5,\n",
    "        in_channels=1,\n",
    "        classes=10,\n",
    "    ):\n",
    "        super(AdjustedFashionCNN, self).__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.input_size = input_size\n",
    "        self.pool_kernel_size = 3\n",
    "        self.pool_stride = 3\n",
    "\n",
    "        # Compute output sizes after conv and pool operations\n",
    "        conv1_out_size = self.input_size - self.kernel_size + 1\n",
    "        pool1_out_size = (\n",
    "            conv1_out_size - self.pool_kernel_size\n",
    "        ) // self.pool_stride + 1\n",
    "\n",
    "        conv2_input_size = pool1_out_size\n",
    "        conv2_out_size = conv2_input_size - self.kernel_size + 1\n",
    "        pool2_out_size = (\n",
    "            conv2_out_size - self.pool_kernel_size\n",
    "        ) // self.pool_stride + 1\n",
    "\n",
    "        fc_input_size = num_filters2 * pool2_out_size * pool2_out_size\n",
    "        print(fc_input_size)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=num_filters1,\n",
    "                kernel_size=self.kernel_size,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_filters1),\n",
    "            nn.MaxPool2d(kernel_size=self.pool_kernel_size, stride=self.pool_stride),\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=num_filters1,\n",
    "                out_channels=num_filters2,\n",
    "                kernel_size=self.kernel_size,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_filters2),\n",
    "            nn.MaxPool2d(kernel_size=self.pool_kernel_size, stride=self.pool_stride),\n",
    "        )\n",
    "        self.drop = nn.Dropout2d(dropout_rate)\n",
    "        self.fc1 = nn.Linear(fc_input_size, classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Adjusted train function\n",
    "def train(model, data_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, labels in data_loader:  # Unpacking tumor_border and tumor_mask\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    return accuracy, average_loss\n",
    "\n",
    "\n",
    "# Adjusted test function\n",
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:  # Unpacking tumor_border and tumor_mask\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    return accuracy, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Accuracy: 63.18%, Test Accuracy: 70.58%, Train Loss: 0.9094, Test Loss: 0.8416\n",
      "Epoch [2/30], Train Accuracy: 71.39%, Test Accuracy: 72.46%, Train Loss: 0.8346, Test Loss: 0.8229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ahmadar/Downloads/ML/ML-Project.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_accuracies, test_accuracies, train_losses, test_losses \u001b[39m=\u001b[39m [], [], [], []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     train_accuracy, train_loss \u001b[39m=\u001b[39m train(model, train_loader, criterion, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     test_accuracy, test_loss \u001b[39m=\u001b[39m test(model, test_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     train_accuracies\u001b[39m.\u001b[39mappend(train_accuracy)\n",
      "\u001b[1;32m/Users/ahmadar/Downloads/ML/ML-Project.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m images, labels \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/ahmadar/Downloads/ML/ML-Project.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer2(out)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mview(out\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X32sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop(out)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2452\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MAT SETUP\n",
    "model = AdjustedFashionCNN(input_size=227, classes=3, in_channels=1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "# Training the model and capturing metrics\n",
    "num_epochs = 30\n",
    "train_accuracies, test_accuracies, train_losses, test_losses = [], [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_accuracy, train_loss = train(model, train_loader, criterion, optimizer)\n",
    "    test_accuracy, test_loss = test(model, test_loader)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "print(\"Training and testing completed!\")\n",
    "\n",
    "# Visualizing the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies, \"k\", label=\"Training Accuracy\")\n",
    "plt.plot(test_accuracies, \"r\", label=\"Testing Accuracy\")\n",
    "plt.title(\"Training and Testing Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, \"k\", label=\"Training Loss\")\n",
    "plt.plot(test_losses, \"r\", label=\"Testing Loss\")\n",
    "plt.title(\"Training and Test Loss over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\", download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.2860410809516907\n",
      "Standard Deviation: 0.3530237078666687\n"
     ]
    }
   ],
   "source": [
    "# Initializing variables to store sum and squared sum\n",
    "total_sum = 0\n",
    "total_squared_sum = 0\n",
    "num_pixels = 0\n",
    "\n",
    "# Calculating mean and standard deviation\n",
    "for data, _ in train_set:\n",
    "    total_sum += data.sum()\n",
    "    total_squared_sum += (data**2).sum()\n",
    "    num_pixels += data.numel()\n",
    "\n",
    "mean = total_sum / num_pixels\n",
    "std_dev = (total_squared_sum / num_pixels - mean**2) ** 0.5\n",
    "\n",
    "print(f\"Mean: {mean.item()}\")\n",
    "print(f\"Standard Deviation: {std_dev.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assuming these are the calculated mean and standard deviation values\n",
    "mean_value = mean.item()  # replace with the calculated mean value\n",
    "std_value = std_dev.item()  # replace with the calculated std deviation value\n",
    "\n",
    "# Updated transformations with normalization\n",
    "transforming_img = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((mean_value,), (std_value,))]\n",
    ")\n",
    "\n",
    "# Loading the FashionMNIST datasets with the updated transformations\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\", download=True, transform=transforming_img\n",
    ")\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\", download=True, train=False, transform=transforming_img\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "        0: \"T-shirt/Top\",\n",
    "        1: \"Trouser\",\n",
    "        2: \"Pullover\",\n",
    "        3: \"Dress\",\n",
    "        4: \"Coat\",\n",
    "        5: \"Sandal\",\n",
    "        6: \"Shirt\",\n",
    "        7: \"Sneaker\",\n",
    "        8: \"Bag\",\n",
    "        9: \"Ankle Boot\",\n",
    "    }\n",
    "    input = label.item() if type(label) == torch.Tensor else label\n",
    "    return output_mapping[input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = next(iter(train_loader))\n",
    "a[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(train_set))\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([10, 1, 28, 28]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "demo_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n",
    "\n",
    "batch = next(iter(demo_loader))\n",
    "images, labels = batch\n",
    "print(type(images), type(labels))\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([10, 1, 28, 28]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "demo_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n",
    "\n",
    "batch = next(iter(demo_loader))\n",
    "images, labels = batch\n",
    "print(type(images), type(labels))\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdjustedFashionCNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the adjusted model with a kernel size of 3 (for example) and print its architecture\n",
    "adjusted_fashion_model = AdjustedFashionCNN(kernel_size=5)\n",
    "adjusted_fashion_model\n",
    "\n",
    "# Check if GPU is available and move the model to GPU if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "adjusted_fashion_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "Epoch [1/30], Train Accuracy: 77.17%, Test Accuracy: 82.72%, Train Loss: 1.7083, Test Loss: 1.6382\n",
      "Epoch [2/30], Train Accuracy: 81.85%, Test Accuracy: 84.60%, Train Loss: 1.6492, Test Loss: 1.6183\n",
      "Epoch [3/30], Train Accuracy: 83.59%, Test Accuracy: 85.03%, Train Loss: 1.6297, Test Loss: 1.6125\n",
      "Epoch [4/30], Train Accuracy: 84.68%, Test Accuracy: 86.25%, Train Loss: 1.6182, Test Loss: 1.6006\n",
      "Epoch [5/30], Train Accuracy: 85.31%, Test Accuracy: 86.65%, Train Loss: 1.6110, Test Loss: 1.5950\n",
      "Epoch [6/30], Train Accuracy: 85.83%, Test Accuracy: 86.84%, Train Loss: 1.6055, Test Loss: 1.5942\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ahmadar/Downloads/ML/ML-Project.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_accuracies, test_accuracies, train_losses, test_losses \u001b[39m=\u001b[39m [], [], [], []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     train_accuracy, train_loss \u001b[39m=\u001b[39m train(model, train_loader, criterion, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     test_accuracy, test_loss \u001b[39m=\u001b[39m test(model, test_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     train_accuracies\u001b[39m.\u001b[39mappend(train_accuracy)\n",
      "\u001b[1;32m/Users/ahmadar/Downloads/ML/ML-Project.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m data_loader:  \u001b[39m# Unpacking tumor_border and tumor_mask\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     images, labels \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmadar/Downloads/ML/ML-Project.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/functional.py:166\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    165\u001b[0m mode_to_nptype \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mint32, \u001b[39m\"\u001b[39m\u001b[39mI;16\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mint16, \u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mfloat32}\n\u001b[0;32m--> 166\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(np\u001b[39m.\u001b[39;49marray(pic, mode_to_nptype\u001b[39m.\u001b[39;49mget(pic\u001b[39m.\u001b[39;49mmode, np\u001b[39m.\u001b[39;49muint8), copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model, loss function, optimizer initialization\n",
    "model = AdjustedFashionCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "# Training the model and capturing metrics\n",
    "num_epochs = 30\n",
    "train_accuracies, test_accuracies, train_losses, test_losses = [], [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_accuracy, train_loss = train(model, train_loader, criterion, optimizer)\n",
    "    test_accuracy, test_loss = test(model, test_loader)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "print(\"Training and testing completed!\")\n",
    "\n",
    "# Visualizing the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies, \"k\", label=\"Training Accuracy\")\n",
    "plt.plot(test_accuracies, \"r\", label=\"Testing Accuracy\")\n",
    "plt.title(\"Training and Testing Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, \"k\", label=\"Training Loss\")\n",
    "plt.plot(test_losses, \"r\", label=\"Testing Loss\")\n",
    "plt.title(\"Training and Test Loss over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to predict and plot\n",
    "def predict_and_plot(model, data_loader, num_images=5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(data_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(images.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 5, 5, images_so_far)\n",
    "                ax.axis(\"off\")\n",
    "                ax.set_title(f\"Predicted: {preds[j]}, True: {labels[j]}\")\n",
    "                img = images.cpu().data[j].numpy().transpose((1, 2, 0))\n",
    "                plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    return\n",
    "\n",
    "\n",
    "# Predict and plot using the test data\n",
    "predict_and_plot(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration 1/144:\n",
      "LR: 0.1, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.48% - Train Loss: 0.4945\n",
      "Test Accuracy: 82.82% - Test Loss: 0.4577\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.59% - Train Loss: 0.3198\n",
      "Test Accuracy: 88.66% - Test Loss: 0.3154\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.86% - Train Loss: 0.2787\n",
      "Test Accuracy: 89.30% - Test Loss: 0.3063\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.64% - Train Loss: 0.2555\n",
      "Test Accuracy: 89.96% - Test Loss: 0.2876\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.31% - Train Loss: 0.2382\n",
      "Test Accuracy: 89.95% - Test Loss: 0.2945\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 2/144:\n",
      "LR: 0.1, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.07% - Train Loss: 0.4703\n",
      "Test Accuracy: 85.36% - Test Loss: 0.4053\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.32% - Train Loss: 0.3224\n",
      "Test Accuracy: 87.87% - Test Loss: 0.3329\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.88% - Train Loss: 0.2792\n",
      "Test Accuracy: 88.61% - Test Loss: 0.3088\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.80% - Train Loss: 0.2536\n",
      "Test Accuracy: 88.95% - Test Loss: 0.3027\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.54% - Train Loss: 0.2341\n",
      "Test Accuracy: 89.12% - Test Loss: 0.2962\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 3/144:\n",
      "LR: 0.1, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.64% - Train Loss: 0.4788\n",
      "Test Accuracy: 85.16% - Test Loss: 0.4067\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.84% - Train Loss: 0.3380\n",
      "Test Accuracy: 87.96% - Test Loss: 0.3343\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.38% - Train Loss: 0.2936\n",
      "Test Accuracy: 88.78% - Test Loss: 0.3135\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.38% - Train Loss: 0.2655\n",
      "Test Accuracy: 89.10% - Test Loss: 0.3068\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.19% - Train Loss: 0.2435\n",
      "Test Accuracy: 89.50% - Test Loss: 0.3023\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 4/144:\n",
      "LR: 0.1, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.48% - Train Loss: 0.4565\n",
      "Test Accuracy: 86.00% - Test Loss: 0.3866\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.71% - Train Loss: 0.3128\n",
      "Test Accuracy: 88.93% - Test Loss: 0.3180\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.46% - Train Loss: 0.2645\n",
      "Test Accuracy: 89.31% - Test Loss: 0.3105\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 91.53% - Train Loss: 0.2344\n",
      "Test Accuracy: 90.01% - Test Loss: 0.2972\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 92.37% - Train Loss: 0.2107\n",
      "Test Accuracy: 89.82% - Test Loss: 0.3007\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 5/144:\n",
      "LR: 0.1, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 6/144:\n",
      "LR: 0.1, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.20% - Train Loss: 0.4997\n",
      "Test Accuracy: 83.06% - Test Loss: 0.4435\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.00% - Train Loss: 0.3334\n",
      "Test Accuracy: 87.73% - Test Loss: 0.3358\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.64% - Train Loss: 0.2905\n",
      "Test Accuracy: 88.67% - Test Loss: 0.3079\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.38% - Train Loss: 0.2666\n",
      "Test Accuracy: 89.21% - Test Loss: 0.2994\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.95% - Train Loss: 0.2488\n",
      "Test Accuracy: 88.84% - Test Loss: 0.2999\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 7/144:\n",
      "LR: 0.1, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.55% - Train Loss: 0.5115\n",
      "Test Accuracy: 85.05% - Test Loss: 0.4146\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.39% - Train Loss: 0.3527\n",
      "Test Accuracy: 87.46% - Test Loss: 0.3495\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.99% - Train Loss: 0.3054\n",
      "Test Accuracy: 88.01% - Test Loss: 0.3354\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.88% - Train Loss: 0.2779\n",
      "Test Accuracy: 88.51% - Test Loss: 0.3172\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.75% - Train Loss: 0.2574\n",
      "Test Accuracy: 88.75% - Test Loss: 0.3181\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 8/144:\n",
      "LR: 0.1, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.00% - Train Loss: 0.4999\n",
      "Test Accuracy: 84.76% - Test Loss: 0.4141\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.34% - Train Loss: 0.3284\n",
      "Test Accuracy: 87.22% - Test Loss: 0.3441\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.06% - Train Loss: 0.2776\n",
      "Test Accuracy: 89.11% - Test Loss: 0.3017\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.99% - Train Loss: 0.2492\n",
      "Test Accuracy: 88.63% - Test Loss: 0.3217\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.94% - Train Loss: 0.2248\n",
      "Test Accuracy: 89.67% - Test Loss: 0.2983\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 9/144:\n",
      "LR: 0.1, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 10/144:\n",
      "LR: 0.1, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 11/144:\n",
      "LR: 0.1, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 12/144:\n",
      "LR: 0.1, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 13/144:\n",
      "LR: 0.1, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 14/144:\n",
      "LR: 0.1, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 15/144:\n",
      "LR: 0.1, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 16/144:\n",
      "LR: 0.1, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 17/144:\n",
      "LR: 0.1, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.58% - Train Loss: 0.4821\n",
      "Test Accuracy: 76.92% - Test Loss: 0.6960\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.90% - Train Loss: 0.3366\n",
      "Test Accuracy: 81.45% - Test Loss: 0.5161\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.25% - Train Loss: 0.2973\n",
      "Test Accuracy: 81.83% - Test Loss: 0.5176\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.16% - Train Loss: 0.2715\n",
      "Test Accuracy: 86.12% - Test Loss: 0.3846\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.82% - Train Loss: 0.2517\n",
      "Test Accuracy: 85.41% - Test Loss: 0.4126\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 18/144:\n",
      "LR: 0.1, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.91% - Train Loss: 0.4727\n",
      "Test Accuracy: 81.80% - Test Loss: 0.4832\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.87% - Train Loss: 0.3343\n",
      "Test Accuracy: 85.15% - Test Loss: 0.3979\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.30% - Train Loss: 0.2945\n",
      "Test Accuracy: 83.97% - Test Loss: 0.4296\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.31% - Train Loss: 0.2681\n",
      "Test Accuracy: 85.95% - Test Loss: 0.3827\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.02% - Train Loss: 0.2478\n",
      "Test Accuracy: 85.45% - Test Loss: 0.3951\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 19/144:\n",
      "LR: 0.1, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.51% - Train Loss: 0.4821\n",
      "Test Accuracy: 81.81% - Test Loss: 0.4841\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.64% - Train Loss: 0.3420\n",
      "Test Accuracy: 84.70% - Test Loss: 0.4052\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.11% - Train Loss: 0.3010\n",
      "Test Accuracy: 84.95% - Test Loss: 0.3953\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.06% - Train Loss: 0.2732\n",
      "Test Accuracy: 84.28% - Test Loss: 0.4175\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.85% - Train Loss: 0.2519\n",
      "Test Accuracy: 85.92% - Test Loss: 0.3850\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 20/144:\n",
      "LR: 0.1, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.20% - Train Loss: 0.4638\n",
      "Test Accuracy: 84.41% - Test Loss: 0.4144\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.41% - Train Loss: 0.3211\n",
      "Test Accuracy: 86.26% - Test Loss: 0.3660\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.04% - Train Loss: 0.2774\n",
      "Test Accuracy: 88.42% - Test Loss: 0.3242\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 91.05% - Train Loss: 0.2474\n",
      "Test Accuracy: 88.60% - Test Loss: 0.3196\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.91% - Train Loss: 0.2241\n",
      "Test Accuracy: 89.86% - Test Loss: 0.2881\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 21/144:\n",
      "LR: 0.1, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.88% - Train Loss: 0.5402\n",
      "Test Accuracy: 80.26% - Test Loss: 0.5185\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.44% - Train Loss: 0.3507\n",
      "Test Accuracy: 78.19% - Test Loss: 0.6392\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.04% - Train Loss: 0.3037\n",
      "Test Accuracy: 81.02% - Test Loss: 0.5345\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.01% - Train Loss: 0.2759\n",
      "Test Accuracy: 85.11% - Test Loss: 0.4048\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.73% - Train Loss: 0.2565\n",
      "Test Accuracy: 88.26% - Test Loss: 0.3256\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 22/144:\n",
      "LR: 0.1, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.76% - Train Loss: 0.5042\n",
      "Test Accuracy: 82.02% - Test Loss: 0.4701\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.09% - Train Loss: 0.3570\n",
      "Test Accuracy: 83.05% - Test Loss: 0.4424\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.57% - Train Loss: 0.3138\n",
      "Test Accuracy: 85.80% - Test Loss: 0.3804\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.73% - Train Loss: 0.2840\n",
      "Test Accuracy: 85.89% - Test Loss: 0.3801\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.56% - Train Loss: 0.2633\n",
      "Test Accuracy: 88.02% - Test Loss: 0.3269\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 23/144:\n",
      "LR: 0.1, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.55% - Train Loss: 0.5023\n",
      "Test Accuracy: 81.56% - Test Loss: 0.4783\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.11% - Train Loss: 0.3578\n",
      "Test Accuracy: 82.49% - Test Loss: 0.4654\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.54% - Train Loss: 0.3153\n",
      "Test Accuracy: 84.29% - Test Loss: 0.4200\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.73% - Train Loss: 0.2848\n",
      "Test Accuracy: 85.70% - Test Loss: 0.3857\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.42% - Train Loss: 0.2644\n",
      "Test Accuracy: 88.20% - Test Loss: 0.3329\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 24/144:\n",
      "LR: 0.1, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.51% - Train Loss: 0.4828\n",
      "Test Accuracy: 82.44% - Test Loss: 0.4702\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.89% - Train Loss: 0.3366\n",
      "Test Accuracy: 85.33% - Test Loss: 0.3931\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.61% - Train Loss: 0.2931\n",
      "Test Accuracy: 86.12% - Test Loss: 0.3667\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.57% - Train Loss: 0.2620\n",
      "Test Accuracy: 87.43% - Test Loss: 0.3398\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.42% - Train Loss: 0.2375\n",
      "Test Accuracy: 89.80% - Test Loss: 0.2922\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 25/144:\n",
      "LR: 0.1, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 26/144:\n",
      "LR: 0.1, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 27/144:\n",
      "LR: 0.1, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 28/144:\n",
      "LR: 0.1, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 29/144:\n",
      "LR: 0.1, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 30/144:\n",
      "LR: 0.1, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 31/144:\n",
      "LR: 0.1, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 32/144:\n",
      "LR: 0.1, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 33/144:\n",
      "LR: 0.1, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.67% - Train Loss: 0.5052\n",
      "Test Accuracy: 81.19% - Test Loss: 0.5420\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.57% - Train Loss: 0.3466\n",
      "Test Accuracy: 85.49% - Test Loss: 0.4003\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.94% - Train Loss: 0.3056\n",
      "Test Accuracy: 88.01% - Test Loss: 0.3357\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.83% - Train Loss: 0.2799\n",
      "Test Accuracy: 88.23% - Test Loss: 0.3302\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.50% - Train Loss: 0.2613\n",
      "Test Accuracy: 89.46% - Test Loss: 0.3012\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 34/144:\n",
      "LR: 0.1, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.80% - Train Loss: 0.5007\n",
      "Test Accuracy: 85.82% - Test Loss: 0.3868\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.25% - Train Loss: 0.3496\n",
      "Test Accuracy: 87.65% - Test Loss: 0.3378\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.75% - Train Loss: 0.3086\n",
      "Test Accuracy: 87.56% - Test Loss: 0.3413\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.72% - Train Loss: 0.2836\n",
      "Test Accuracy: 88.09% - Test Loss: 0.3246\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.46% - Train Loss: 0.2641\n",
      "Test Accuracy: 89.17% - Test Loss: 0.3058\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 35/144:\n",
      "LR: 0.1, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.32% - Train Loss: 0.5123\n",
      "Test Accuracy: 85.39% - Test Loss: 0.3954\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.05% - Train Loss: 0.3559\n",
      "Test Accuracy: 86.46% - Test Loss: 0.3659\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.64% - Train Loss: 0.3111\n",
      "Test Accuracy: 87.37% - Test Loss: 0.3399\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.63% - Train Loss: 0.2853\n",
      "Test Accuracy: 87.80% - Test Loss: 0.3260\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.41% - Train Loss: 0.2638\n",
      "Test Accuracy: 88.59% - Test Loss: 0.3107\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 36/144:\n",
      "LR: 0.1, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.07% - Train Loss: 0.4951\n",
      "Test Accuracy: 85.72% - Test Loss: 0.3897\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.86% - Train Loss: 0.3349\n",
      "Test Accuracy: 87.05% - Test Loss: 0.3541\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.65% - Train Loss: 0.2895\n",
      "Test Accuracy: 88.26% - Test Loss: 0.3258\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.64% - Train Loss: 0.2605\n",
      "Test Accuracy: 87.43% - Test Loss: 0.3444\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.37% - Train Loss: 0.2374\n",
      "Test Accuracy: 88.25% - Test Loss: 0.3269\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 37/144:\n",
      "LR: 0.1, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.60% - Train Loss: 0.5328\n",
      "Test Accuracy: 82.84% - Test Loss: 0.4761\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 86.66% - Train Loss: 0.3693\n",
      "Test Accuracy: 83.72% - Test Loss: 0.4385\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.24% - Train Loss: 0.3260\n",
      "Test Accuracy: 88.09% - Test Loss: 0.3341\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.12% - Train Loss: 0.2994\n",
      "Test Accuracy: 87.06% - Test Loss: 0.3589\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 89.79% - Train Loss: 0.2787\n",
      "Test Accuracy: 88.58% - Test Loss: 0.3185\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 38/144:\n",
      "LR: 0.1, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.82% - Train Loss: 0.5231\n",
      "Test Accuracy: 86.21% - Test Loss: 0.3806\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 86.72% - Train Loss: 0.3644\n",
      "Test Accuracy: 86.51% - Test Loss: 0.3618\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.40% - Train Loss: 0.3214\n",
      "Test Accuracy: 87.55% - Test Loss: 0.3392\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.25% - Train Loss: 0.2948\n",
      "Test Accuracy: 87.83% - Test Loss: 0.3229\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 89.97% - Train Loss: 0.2759\n",
      "Test Accuracy: 89.08% - Test Loss: 0.2952\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 39/144:\n",
      "LR: 0.1, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.99% - Train Loss: 0.5212\n",
      "Test Accuracy: 85.68% - Test Loss: 0.3893\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 86.58% - Train Loss: 0.3695\n",
      "Test Accuracy: 86.56% - Test Loss: 0.3611\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 87.97% - Train Loss: 0.3283\n",
      "Test Accuracy: 87.34% - Test Loss: 0.3403\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 88.99% - Train Loss: 0.3009\n",
      "Test Accuracy: 87.15% - Test Loss: 0.3469\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 89.88% - Train Loss: 0.2793\n",
      "Test Accuracy: 87.58% - Test Loss: 0.3414\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 40/144:\n",
      "LR: 0.1, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.63% - Train Loss: 0.5061\n",
      "Test Accuracy: 86.97% - Test Loss: 0.3667\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.57% - Train Loss: 0.3452\n",
      "Test Accuracy: 87.71% - Test Loss: 0.3395\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.18% - Train Loss: 0.3006\n",
      "Test Accuracy: 88.68% - Test Loss: 0.3184\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.30% - Train Loss: 0.2705\n",
      "Test Accuracy: 88.72% - Test Loss: 0.3184\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.06% - Train Loss: 0.2479\n",
      "Test Accuracy: 89.08% - Test Loss: 0.3123\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 41/144:\n",
      "LR: 0.1, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 42/144:\n",
      "LR: 0.1, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 43/144:\n",
      "LR: 0.1, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 44/144:\n",
      "LR: 0.1, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 45/144:\n",
      "LR: 0.1, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 46/144:\n",
      "LR: 0.1, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 47/144:\n",
      "LR: 0.1, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 48/144:\n",
      "LR: 0.1, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 49/144:\n",
      "LR: 0.01, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.41% - Train Loss: 0.4759\n",
      "Test Accuracy: 86.87% - Test Loss: 0.3650\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.42% - Train Loss: 0.3246\n",
      "Test Accuracy: 88.16% - Test Loss: 0.3275\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.54% - Train Loss: 0.2912\n",
      "Test Accuracy: 89.05% - Test Loss: 0.3019\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.33% - Train Loss: 0.2692\n",
      "Test Accuracy: 89.73% - Test Loss: 0.2912\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.89% - Train Loss: 0.2541\n",
      "Test Accuracy: 89.80% - Test Loss: 0.2875\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 50/144:\n",
      "LR: 0.01, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.66% - Train Loss: 0.4996\n",
      "Test Accuracy: 86.38% - Test Loss: 0.3790\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.98% - Train Loss: 0.3385\n",
      "Test Accuracy: 87.80% - Test Loss: 0.3344\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.30% - Train Loss: 0.2993\n",
      "Test Accuracy: 88.58% - Test Loss: 0.3147\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.04% - Train Loss: 0.2757\n",
      "Test Accuracy: 88.96% - Test Loss: 0.3080\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.72% - Train Loss: 0.2576\n",
      "Test Accuracy: 89.25% - Test Loss: 0.2951\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 51/144:\n",
      "LR: 0.01, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.34% - Train Loss: 0.5357\n",
      "Test Accuracy: 85.56% - Test Loss: 0.3950\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.29% - Train Loss: 0.3534\n",
      "Test Accuracy: 86.66% - Test Loss: 0.3590\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.75% - Train Loss: 0.3122\n",
      "Test Accuracy: 87.53% - Test Loss: 0.3355\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.55% - Train Loss: 0.2871\n",
      "Test Accuracy: 87.82% - Test Loss: 0.3238\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.33% - Train Loss: 0.2678\n",
      "Test Accuracy: 88.19% - Test Loss: 0.3141\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 52/144:\n",
      "LR: 0.01, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.06% - Train Loss: 0.5072\n",
      "Test Accuracy: 87.18% - Test Loss: 0.3658\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.17% - Train Loss: 0.3298\n",
      "Test Accuracy: 88.32% - Test Loss: 0.3280\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.63% - Train Loss: 0.2885\n",
      "Test Accuracy: 89.25% - Test Loss: 0.3049\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.70% - Train Loss: 0.2600\n",
      "Test Accuracy: 89.70% - Test Loss: 0.2931\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.45% - Train Loss: 0.2379\n",
      "Test Accuracy: 89.79% - Test Loss: 0.2871\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 53/144:\n",
      "LR: 0.01, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.27% - Train Loss: 0.4988\n",
      "Test Accuracy: 86.04% - Test Loss: 0.3850\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.42% - Train Loss: 0.3503\n",
      "Test Accuracy: 87.74% - Test Loss: 0.3358\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.72% - Train Loss: 0.3127\n",
      "Test Accuracy: 88.94% - Test Loss: 0.3061\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.53% - Train Loss: 0.2919\n",
      "Test Accuracy: 89.22% - Test Loss: 0.2966\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.10% - Train Loss: 0.2749\n",
      "Test Accuracy: 89.60% - Test Loss: 0.2909\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 54/144:\n",
      "LR: 0.01, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.52% - Train Loss: 0.5245\n",
      "Test Accuracy: 86.07% - Test Loss: 0.3869\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.16% - Train Loss: 0.3572\n",
      "Test Accuracy: 87.62% - Test Loss: 0.3420\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.71% - Train Loss: 0.3153\n",
      "Test Accuracy: 88.47% - Test Loss: 0.3226\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.60% - Train Loss: 0.2919\n",
      "Test Accuracy: 88.72% - Test Loss: 0.3099\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.15% - Train Loss: 0.2746\n",
      "Test Accuracy: 89.03% - Test Loss: 0.3069\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 55/144:\n",
      "LR: 0.01, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.74% - Train Loss: 0.5514\n",
      "Test Accuracy: 85.85% - Test Loss: 0.3952\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 86.82% - Train Loss: 0.3656\n",
      "Test Accuracy: 86.92% - Test Loss: 0.3556\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.38% - Train Loss: 0.3244\n",
      "Test Accuracy: 88.12% - Test Loss: 0.3343\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.26% - Train Loss: 0.2972\n",
      "Test Accuracy: 88.22% - Test Loss: 0.3259\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 89.91% - Train Loss: 0.2788\n",
      "Test Accuracy: 88.27% - Test Loss: 0.3219\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 56/144:\n",
      "LR: 0.01, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.83% - Train Loss: 0.5171\n",
      "Test Accuracy: 86.60% - Test Loss: 0.3762\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.60% - Train Loss: 0.3431\n",
      "Test Accuracy: 87.93% - Test Loss: 0.3321\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.15% - Train Loss: 0.3032\n",
      "Test Accuracy: 89.03% - Test Loss: 0.3095\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.98% - Train Loss: 0.2783\n",
      "Test Accuracy: 89.13% - Test Loss: 0.2970\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.70% - Train Loss: 0.2569\n",
      "Test Accuracy: 89.68% - Test Loss: 0.2888\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 57/144:\n",
      "LR: 0.01, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.07% - Train Loss: 1.3782\n",
      "Test Accuracy: 87.33% - Test Loss: 0.3531\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 86.15% - Train Loss: 0.3902\n",
      "Test Accuracy: 86.19% - Test Loss: 0.3972\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 84.92% - Train Loss: 0.4339\n",
      "Test Accuracy: 84.01% - Test Loss: 0.5050\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 83.91% - Train Loss: 0.4653\n",
      "Test Accuracy: 82.31% - Test Loss: 0.5053\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 81.83% - Train Loss: 0.5247\n",
      "Test Accuracy: 83.18% - Test Loss: 0.5014\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 58/144:\n",
      "LR: 0.01, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.88% - Train Loss: 1.1996\n",
      "Test Accuracy: 86.86% - Test Loss: 0.3752\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 85.63% - Train Loss: 0.4074\n",
      "Test Accuracy: 85.99% - Test Loss: 0.4094\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 84.76% - Train Loss: 0.4398\n",
      "Test Accuracy: 84.22% - Test Loss: 0.4582\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 83.72% - Train Loss: 0.4722\n",
      "Test Accuracy: 84.53% - Test Loss: 0.4676\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 82.98% - Train Loss: 0.4981\n",
      "Test Accuracy: 84.02% - Test Loss: 0.4694\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 59/144:\n",
      "LR: 0.01, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 60/144:\n",
      "LR: 0.01, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.64% - Train Loss: 0.8038\n",
      "Test Accuracy: 85.87% - Test Loss: 0.4105\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 85.09% - Train Loss: 0.4288\n",
      "Test Accuracy: 85.87% - Test Loss: 0.3954\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 84.58% - Train Loss: 0.4555\n",
      "Test Accuracy: 84.55% - Test Loss: 0.4511\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 84.06% - Train Loss: 0.4783\n",
      "Test Accuracy: 81.05% - Test Loss: 0.6019\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 83.64% - Train Loss: 0.4970\n",
      "Test Accuracy: 84.39% - Test Loss: 0.4971\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 61/144:\n",
      "LR: 0.01, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.25% - Train Loss: 1.4243\n",
      "Test Accuracy: 86.16% - Test Loss: 0.3860\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 85.31% - Train Loss: 0.4142\n",
      "Test Accuracy: 81.94% - Test Loss: 0.4778\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 83.17% - Train Loss: 0.4895\n",
      "Test Accuracy: 80.06% - Test Loss: 0.5662\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 80.83% - Train Loss: 0.5530\n",
      "Test Accuracy: 82.02% - Test Loss: 0.5361\n",
      "----------------------------------------\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 62/144:\n",
      "LR: 0.01, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.19% - Train Loss: 1.1905\n",
      "Test Accuracy: 85.83% - Test Loss: 0.4117\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 84.66% - Train Loss: 0.4331\n",
      "Test Accuracy: 82.55% - Test Loss: 0.5433\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 83.53% - Train Loss: 0.4799\n",
      "Test Accuracy: 83.21% - Test Loss: 0.5138\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 80.69% - Train Loss: 0.5815\n",
      "Test Accuracy: 82.47% - Test Loss: 0.5446\n",
      "----------------------------------------\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 63/144:\n",
      "LR: 0.01, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 64/144:\n",
      "LR: 0.01, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 65/144:\n",
      "LR: 0.01, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 81.63% - Train Loss: 0.5458\n",
      "Test Accuracy: 85.56% - Test Loss: 0.4021\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.27% - Train Loss: 0.3568\n",
      "Test Accuracy: 86.76% - Test Loss: 0.3621\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.73% - Train Loss: 0.3171\n",
      "Test Accuracy: 87.11% - Test Loss: 0.3432\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.56% - Train Loss: 0.2939\n",
      "Test Accuracy: 87.33% - Test Loss: 0.3401\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.09% - Train Loss: 0.2766\n",
      "Test Accuracy: 87.78% - Test Loss: 0.3300\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 66/144:\n",
      "LR: 0.01, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 67/144:\n",
      "LR: 0.01, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 68/144:\n",
      "LR: 0.01, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 69/144:\n",
      "LR: 0.01, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.65% - Train Loss: 0.5669\n",
      "Test Accuracy: 85.23% - Test Loss: 0.4124\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 86.78% - Train Loss: 0.3727\n",
      "Test Accuracy: 86.81% - Test Loss: 0.3642\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.11% - Train Loss: 0.3306\n",
      "Test Accuracy: 87.41% - Test Loss: 0.3411\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.08% - Train Loss: 0.3063\n",
      "Test Accuracy: 87.90% - Test Loss: 0.3277\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 89.54% - Train Loss: 0.2898\n",
      "Test Accuracy: 88.64% - Test Loss: 0.3115\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 70/144:\n",
      "LR: 0.01, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 71/144:\n",
      "LR: 0.01, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 72/144:\n",
      "LR: 0.01, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 73/144:\n",
      "LR: 0.01, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.54% - Train Loss: 2.4610\n",
      "Test Accuracy: 83.28% - Test Loss: 0.4445\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.56% - Train Loss: 0.3440\n",
      "Test Accuracy: 85.63% - Test Loss: 0.3880\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.47% - Train Loss: 0.3160\n",
      "Test Accuracy: 85.03% - Test Loss: 0.4076\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 88.90% - Train Loss: 0.3062\n",
      "Test Accuracy: 86.89% - Test Loss: 0.3657\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 88.93% - Train Loss: 0.3084\n",
      "Test Accuracy: 88.34% - Test Loss: 0.3514\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 74/144:\n",
      "LR: 0.01, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.56% - Train Loss: 1.4993\n",
      "Test Accuracy: 82.72% - Test Loss: 0.5037\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.46% - Train Loss: 0.3511\n",
      "Test Accuracy: 86.17% - Test Loss: 0.3747\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.18% - Train Loss: 0.3255\n",
      "Test Accuracy: 85.81% - Test Loss: 0.4101\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 88.23% - Train Loss: 0.3270\n",
      "Test Accuracy: 86.49% - Test Loss: 0.3889\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 88.14% - Train Loss: 0.3328\n",
      "Test Accuracy: 83.60% - Test Loss: 0.5491\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 75/144:\n",
      "LR: 0.01, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 76/144:\n",
      "LR: 0.01, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 77/144:\n",
      "LR: 0.01, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.88% - Train Loss: 2.0321\n",
      "Test Accuracy: 85.97% - Test Loss: 0.3882\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.51% - Train Loss: 0.3465\n",
      "Test Accuracy: 86.03% - Test Loss: 0.3770\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 88.41% - Train Loss: 0.3246\n",
      "Test Accuracy: 87.00% - Test Loss: 0.3563\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 88.14% - Train Loss: 0.3311\n",
      "Test Accuracy: 83.97% - Test Loss: 0.4367\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 87.55% - Train Loss: 0.3491\n",
      "Test Accuracy: 87.30% - Test Loss: 0.3892\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 78/144:\n",
      "LR: 0.01, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 80.06% - Train Loss: 1.4417\n",
      "Test Accuracy: 85.06% - Test Loss: 0.4133\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 86.97% - Train Loss: 0.3644\n",
      "Test Accuracy: 86.31% - Test Loss: 0.3777\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 87.61% - Train Loss: 0.3449\n",
      "Test Accuracy: 87.20% - Test Loss: 0.3640\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 87.40% - Train Loss: 0.3502\n",
      "Test Accuracy: 84.18% - Test Loss: 0.4275\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 87.02% - Train Loss: 0.3656\n",
      "Test Accuracy: 85.76% - Test Loss: 0.4326\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 79/144:\n",
      "LR: 0.01, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 80/144:\n",
      "LR: 0.01, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 81/144:\n",
      "LR: 0.01, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 82/144:\n",
      "LR: 0.01, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 83/144:\n",
      "LR: 0.01, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 84/144:\n",
      "LR: 0.01, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 85/144:\n",
      "LR: 0.01, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 86/144:\n",
      "LR: 0.01, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 87/144:\n",
      "LR: 0.01, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 88/144:\n",
      "LR: 0.01, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 89/144:\n",
      "LR: 0.01, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 90/144:\n",
      "LR: 0.01, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 91/144:\n",
      "LR: 0.01, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 92/144:\n",
      "LR: 0.01, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 93/144:\n",
      "LR: 0.01, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 94/144:\n",
      "LR: 0.01, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 95/144:\n",
      "LR: 0.01, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 96/144:\n",
      "LR: 0.01, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 97/144:\n",
      "LR: 0.001, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 98/144:\n",
      "LR: 0.001, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 99/144:\n",
      "LR: 0.001, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 100/144:\n",
      "LR: 0.001, BS: 32, Optimizer: SGD, Dropout: 0.2, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 101/144:\n",
      "LR: 0.001, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 102/144:\n",
      "LR: 0.001, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 103/144:\n",
      "LR: 0.001, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 104/144:\n",
      "LR: 0.001, BS: 32, Optimizer: SGD, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 105/144:\n",
      "LR: 0.001, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 84.73% - Train Loss: 0.4322\n",
      "Test Accuracy: 87.70% - Test Loss: 0.3348\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.94% - Train Loss: 0.3063\n",
      "Test Accuracy: 89.09% - Test Loss: 0.2975\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.46% - Train Loss: 0.2674\n",
      "Test Accuracy: 89.60% - Test Loss: 0.3058\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 91.26% - Train Loss: 0.2430\n",
      "Test Accuracy: 89.43% - Test Loss: 0.3267\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 92.12% - Train Loss: 0.2216\n",
      "Test Accuracy: 89.71% - Test Loss: 0.3319\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 106/144:\n",
      "LR: 0.001, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 84.42% - Train Loss: 0.4390\n",
      "Test Accuracy: 87.90% - Test Loss: 0.3409\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.86% - Train Loss: 0.3160\n",
      "Test Accuracy: 89.17% - Test Loss: 0.3041\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.08% - Train Loss: 0.2750\n",
      "Test Accuracy: 88.51% - Test Loss: 0.3343\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 91.04% - Train Loss: 0.2490\n",
      "Test Accuracy: 89.72% - Test Loss: 0.3073\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.75% - Train Loss: 0.2277\n",
      "Test Accuracy: 89.52% - Test Loss: 0.3292\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 107/144:\n",
      "LR: 0.001, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.58% - Train Loss: 0.4568\n",
      "Test Accuracy: 86.17% - Test Loss: 0.3911\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.90% - Train Loss: 0.3333\n",
      "Test Accuracy: 87.87% - Test Loss: 0.3507\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.62% - Train Loss: 0.2905\n",
      "Test Accuracy: 87.70% - Test Loss: 0.3673\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.62% - Train Loss: 0.2629\n",
      "Test Accuracy: 87.95% - Test Loss: 0.3719\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.40% - Train Loss: 0.2401\n",
      "Test Accuracy: 88.52% - Test Loss: 0.3643\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 108/144:\n",
      "LR: 0.001, BS: 32, Optimizer: Adam, Dropout: 0.2, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 84.21% - Train Loss: 0.4441\n",
      "Test Accuracy: 87.42% - Test Loss: 0.3557\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.68% - Train Loss: 0.3150\n",
      "Test Accuracy: 87.87% - Test Loss: 0.3467\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.39% - Train Loss: 0.2685\n",
      "Test Accuracy: 88.18% - Test Loss: 0.3517\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 91.44% - Train Loss: 0.2393\n",
      "Test Accuracy: 89.30% - Test Loss: 0.3341\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 92.24% - Train Loss: 0.2151\n",
      "Test Accuracy: 89.29% - Test Loss: 0.3269\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 109/144:\n",
      "LR: 0.001, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.69% - Train Loss: 0.4691\n",
      "Test Accuracy: 86.42% - Test Loss: 0.3682\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.47% - Train Loss: 0.3214\n",
      "Test Accuracy: 87.49% - Test Loss: 0.3441\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.78% - Train Loss: 0.2849\n",
      "Test Accuracy: 88.77% - Test Loss: 0.3215\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.61% - Train Loss: 0.2600\n",
      "Test Accuracy: 89.82% - Test Loss: 0.3021\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.34% - Train Loss: 0.2400\n",
      "Test Accuracy: 90.21% - Test Loss: 0.3091\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 110/144:\n",
      "LR: 0.001, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.63% - Train Loss: 0.4603\n",
      "Test Accuracy: 86.60% - Test Loss: 0.3712\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.25% - Train Loss: 0.3272\n",
      "Test Accuracy: 87.95% - Test Loss: 0.3322\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.62% - Train Loss: 0.2864\n",
      "Test Accuracy: 88.96% - Test Loss: 0.3194\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.60% - Train Loss: 0.2603\n",
      "Test Accuracy: 89.93% - Test Loss: 0.2932\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.34% - Train Loss: 0.2400\n",
      "Test Accuracy: 90.26% - Test Loss: 0.2841\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 111/144:\n",
      "LR: 0.001, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.85% - Train Loss: 0.4799\n",
      "Test Accuracy: 86.72% - Test Loss: 0.3678\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.63% - Train Loss: 0.3436\n",
      "Test Accuracy: 87.64% - Test Loss: 0.3520\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.34% - Train Loss: 0.2992\n",
      "Test Accuracy: 87.87% - Test Loss: 0.3516\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.38% - Train Loss: 0.2698\n",
      "Test Accuracy: 88.70% - Test Loss: 0.3265\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.15% - Train Loss: 0.2482\n",
      "Test Accuracy: 88.47% - Test Loss: 0.3529\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 112/144:\n",
      "LR: 0.001, BS: 32, Optimizer: Adam, Dropout: 0.5, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.43% - Train Loss: 0.4669\n",
      "Test Accuracy: 87.67% - Test Loss: 0.3539\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.50% - Train Loss: 0.3234\n",
      "Test Accuracy: 88.75% - Test Loss: 0.3197\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.07% - Train Loss: 0.2782\n",
      "Test Accuracy: 89.64% - Test Loss: 0.3020\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 91.19% - Train Loss: 0.2459\n",
      "Test Accuracy: 89.59% - Test Loss: 0.3154\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.91% - Train Loss: 0.2241\n",
      "Test Accuracy: 89.24% - Test Loss: 0.3392\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 113/144:\n",
      "LR: 0.001, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 114/144:\n",
      "LR: 0.001, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 115/144:\n",
      "LR: 0.001, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 116/144:\n",
      "LR: 0.001, BS: 64, Optimizer: SGD, Dropout: 0.2, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 117/144:\n",
      "LR: 0.001, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 118/144:\n",
      "LR: 0.001, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 119/144:\n",
      "LR: 0.001, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 120/144:\n",
      "LR: 0.001, BS: 64, Optimizer: SGD, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 121/144:\n",
      "LR: 0.001, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 84.61% - Train Loss: 0.4338\n",
      "Test Accuracy: 86.22% - Test Loss: 0.3672\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 89.07% - Train Loss: 0.3070\n",
      "Test Accuracy: 88.79% - Test Loss: 0.3132\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.26% - Train Loss: 0.2721\n",
      "Test Accuracy: 88.81% - Test Loss: 0.3184\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 91.07% - Train Loss: 0.2485\n",
      "Test Accuracy: 88.51% - Test Loss: 0.3323\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.69% - Train Loss: 0.2303\n",
      "Test Accuracy: 88.11% - Test Loss: 0.3498\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 122/144:\n",
      "LR: 0.001, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 84.25% - Train Loss: 0.4410\n",
      "Test Accuracy: 84.23% - Test Loss: 0.4459\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.56% - Train Loss: 0.3175\n",
      "Test Accuracy: 88.76% - Test Loss: 0.3235\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.89% - Train Loss: 0.2824\n",
      "Test Accuracy: 88.63% - Test Loss: 0.3442\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.66% - Train Loss: 0.2574\n",
      "Test Accuracy: 88.44% - Test Loss: 0.3215\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.54% - Train Loss: 0.2361\n",
      "Test Accuracy: 88.81% - Test Loss: 0.3272\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 123/144:\n",
      "LR: 0.001, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.94% - Train Loss: 0.4475\n",
      "Test Accuracy: 86.12% - Test Loss: 0.3922\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.94% - Train Loss: 0.3308\n",
      "Test Accuracy: 86.41% - Test Loss: 0.3802\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.29% - Train Loss: 0.2938\n",
      "Test Accuracy: 87.32% - Test Loss: 0.3578\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.25% - Train Loss: 0.2665\n",
      "Test Accuracy: 85.66% - Test Loss: 0.4213\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.22% - Train Loss: 0.2436\n",
      "Test Accuracy: 85.31% - Test Loss: 0.4473\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 124/144:\n",
      "LR: 0.001, BS: 64, Optimizer: Adam, Dropout: 0.2, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 84.14% - Train Loss: 0.4380\n",
      "Test Accuracy: 86.65% - Test Loss: 0.3837\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.97% - Train Loss: 0.3097\n",
      "Test Accuracy: 87.33% - Test Loss: 0.3585\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.36% - Train Loss: 0.2690\n",
      "Test Accuracy: 87.81% - Test Loss: 0.3524\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 91.36% - Train Loss: 0.2411\n",
      "Test Accuracy: 87.33% - Test Loss: 0.3751\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 92.22% - Train Loss: 0.2168\n",
      "Test Accuracy: 87.46% - Test Loss: 0.3854\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 125/144:\n",
      "LR: 0.001, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.67% - Train Loss: 0.4650\n",
      "Test Accuracy: 86.69% - Test Loss: 0.3707\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.43% - Train Loss: 0.3226\n",
      "Test Accuracy: 89.07% - Test Loss: 0.3201\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.92% - Train Loss: 0.2820\n",
      "Test Accuracy: 89.86% - Test Loss: 0.2954\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.80% - Train Loss: 0.2561\n",
      "Test Accuracy: 88.59% - Test Loss: 0.3279\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.37% - Train Loss: 0.2394\n",
      "Test Accuracy: 88.52% - Test Loss: 0.3281\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 126/144:\n",
      "LR: 0.001, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.48% - Train Loss: 0.4648\n",
      "Test Accuracy: 86.17% - Test Loss: 0.3859\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.93% - Train Loss: 0.3328\n",
      "Test Accuracy: 88.05% - Test Loss: 0.3438\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.33% - Train Loss: 0.2957\n",
      "Test Accuracy: 87.86% - Test Loss: 0.3472\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.56% - Train Loss: 0.2659\n",
      "Test Accuracy: 85.89% - Test Loss: 0.4015\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.22% - Train Loss: 0.2443\n",
      "Test Accuracy: 86.74% - Test Loss: 0.3745\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 127/144:\n",
      "LR: 0.001, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.11% - Train Loss: 0.4715\n",
      "Test Accuracy: 86.65% - Test Loss: 0.3770\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.69% - Train Loss: 0.3421\n",
      "Test Accuracy: 87.41% - Test Loss: 0.3572\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.02% - Train Loss: 0.3037\n",
      "Test Accuracy: 86.65% - Test Loss: 0.3786\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.18% - Train Loss: 0.2761\n",
      "Test Accuracy: 87.98% - Test Loss: 0.3409\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.03% - Train Loss: 0.2498\n",
      "Test Accuracy: 88.47% - Test Loss: 0.3449\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 128/144:\n",
      "LR: 0.001, BS: 64, Optimizer: Adam, Dropout: 0.5, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.73% - Train Loss: 0.4564\n",
      "Test Accuracy: 86.59% - Test Loss: 0.3816\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.37% - Train Loss: 0.3261\n",
      "Test Accuracy: 86.01% - Test Loss: 0.3946\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.98% - Train Loss: 0.2831\n",
      "Test Accuracy: 86.36% - Test Loss: 0.3973\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.96% - Train Loss: 0.2536\n",
      "Test Accuracy: 88.30% - Test Loss: 0.3507\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.88% - Train Loss: 0.2280\n",
      "Test Accuracy: 87.95% - Test Loss: 0.3660\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 129/144:\n",
      "LR: 0.001, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 130/144:\n",
      "LR: 0.001, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 131/144:\n",
      "LR: 0.001, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 132/144:\n",
      "LR: 0.001, BS: 128, Optimizer: SGD, Dropout: 0.2, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 133/144:\n",
      "LR: 0.001, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 2\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 134/144:\n",
      "LR: 0.001, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 3\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 135/144:\n",
      "LR: 0.001, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 4\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 136/144:\n",
      "LR: 0.001, BS: 128, Optimizer: SGD, Dropout: 0.5, Kernel: 5\n",
      "Train accuracy is less than 80%. Skipping this configuration.\n",
      "------------------------------------------------------\n",
      "Configuration 137/144:\n",
      "LR: 0.001, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 84.29% - Train Loss: 0.4428\n",
      "Test Accuracy: 85.56% - Test Loss: 0.4096\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.94% - Train Loss: 0.3088\n",
      "Test Accuracy: 87.69% - Test Loss: 0.3496\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.12% - Train Loss: 0.2734\n",
      "Test Accuracy: 88.72% - Test Loss: 0.3199\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.95% - Train Loss: 0.2541\n",
      "Test Accuracy: 88.62% - Test Loss: 0.3323\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.34% - Train Loss: 0.2405\n",
      "Test Accuracy: 89.59% - Test Loss: 0.3091\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 138/144:\n",
      "LR: 0.001, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.95% - Train Loss: 0.4445\n",
      "Test Accuracy: 84.96% - Test Loss: 0.4262\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.56% - Train Loss: 0.3181\n",
      "Test Accuracy: 87.30% - Test Loss: 0.3570\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.72% - Train Loss: 0.2832\n",
      "Test Accuracy: 89.58% - Test Loss: 0.2954\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.66% - Train Loss: 0.2577\n",
      "Test Accuracy: 89.62% - Test Loss: 0.2926\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.25% - Train Loss: 0.2407\n",
      "Test Accuracy: 89.61% - Test Loss: 0.2955\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 139/144:\n",
      "LR: 0.001, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.59% - Train Loss: 0.4552\n",
      "Test Accuracy: 85.08% - Test Loss: 0.4182\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.22% - Train Loss: 0.3260\n",
      "Test Accuracy: 88.41% - Test Loss: 0.3299\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.52% - Train Loss: 0.2919\n",
      "Test Accuracy: 87.72% - Test Loss: 0.3455\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.54% - Train Loss: 0.2659\n",
      "Test Accuracy: 87.86% - Test Loss: 0.3495\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.18% - Train Loss: 0.2462\n",
      "Test Accuracy: 87.45% - Test Loss: 0.3789\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 140/144:\n",
      "LR: 0.001, BS: 128, Optimizer: Adam, Dropout: 0.2, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 84.31% - Train Loss: 0.4344\n",
      "Test Accuracy: 85.26% - Test Loss: 0.4135\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.78% - Train Loss: 0.3096\n",
      "Test Accuracy: 87.73% - Test Loss: 0.3456\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.25% - Train Loss: 0.2723\n",
      "Test Accuracy: 88.46% - Test Loss: 0.3362\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 91.09% - Train Loss: 0.2499\n",
      "Test Accuracy: 89.21% - Test Loss: 0.3174\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 92.03% - Train Loss: 0.2254\n",
      "Test Accuracy: 89.63% - Test Loss: 0.3088\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 141/144:\n",
      "LR: 0.001, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 2\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.44% - Train Loss: 0.4678\n",
      "Test Accuracy: 86.59% - Test Loss: 0.3710\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.27% - Train Loss: 0.3287\n",
      "Test Accuracy: 88.74% - Test Loss: 0.3094\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.49% - Train Loss: 0.2920\n",
      "Test Accuracy: 89.47% - Test Loss: 0.2926\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.25% - Train Loss: 0.2687\n",
      "Test Accuracy: 89.61% - Test Loss: 0.3016\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.89% - Train Loss: 0.2539\n",
      "Test Accuracy: 89.91% - Test Loss: 0.2889\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 142/144:\n",
      "LR: 0.001, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 3\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.28% - Train Loss: 0.4641\n",
      "Test Accuracy: 85.99% - Test Loss: 0.3921\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.21% - Train Loss: 0.3306\n",
      "Test Accuracy: 88.34% - Test Loss: 0.3342\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.46% - Train Loss: 0.2940\n",
      "Test Accuracy: 88.65% - Test Loss: 0.3219\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 90.32% - Train Loss: 0.2686\n",
      "Test Accuracy: 88.95% - Test Loss: 0.3190\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.07% - Train Loss: 0.2493\n",
      "Test Accuracy: 89.19% - Test Loss: 0.3151\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 143/144:\n",
      "LR: 0.001, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 4\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 82.59% - Train Loss: 0.4853\n",
      "Test Accuracy: 85.34% - Test Loss: 0.4079\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 87.53% - Train Loss: 0.3470\n",
      "Test Accuracy: 86.61% - Test Loss: 0.3824\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 89.00% - Train Loss: 0.3047\n",
      "Test Accuracy: 87.33% - Test Loss: 0.3679\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 89.95% - Train Loss: 0.2792\n",
      "Test Accuracy: 87.70% - Test Loss: 0.3637\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 90.63% - Train Loss: 0.2597\n",
      "Test Accuracy: 88.02% - Test Loss: 0.3564\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Configuration 144/144:\n",
      "LR: 0.001, BS: 128, Optimizer: Adam, Dropout: 0.5, Kernel: 5\n",
      "Epoch 1/5:\n",
      "Train Accuracy: 83.44% - Train Loss: 0.4649\n",
      "Test Accuracy: 87.36% - Test Loss: 0.3625\n",
      "----------------------------------------\n",
      "Epoch 2/5:\n",
      "Train Accuracy: 88.44% - Train Loss: 0.3232\n",
      "Test Accuracy: 88.40% - Test Loss: 0.3318\n",
      "----------------------------------------\n",
      "Epoch 3/5:\n",
      "Train Accuracy: 90.22% - Train Loss: 0.2791\n",
      "Test Accuracy: 88.50% - Test Loss: 0.3344\n",
      "----------------------------------------\n",
      "Epoch 4/5:\n",
      "Train Accuracy: 91.00% - Train Loss: 0.2541\n",
      "Test Accuracy: 88.39% - Test Loss: 0.3526\n",
      "----------------------------------------\n",
      "Epoch 5/5:\n",
      "Train Accuracy: 91.66% - Train Loss: 0.2332\n",
      "Test Accuracy: 89.44% - Test Loss: 0.3319\n",
      "----------------------------------------\n",
      "------------------------------------------------------\n",
      "Best Test Accuracy: 90.26\n",
      "Best Hyperparameters: {'lr': 0.001, 'batch_size': 32, 'optimizer': <class 'torch.optim.adam.Adam'>, 'dropout_rate': 0.5, 'kernel_size': 3}\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters to tune\n",
    "learning_rates = [0.0001, 0.00001, 0.000001]\n",
    "batch_sizes = [10]\n",
    "\n",
    "optimizers = [torch.optim.SGD, torch.optim.Adam]\n",
    "dropout_rates = [0.2, 0.5]\n",
    "kernel_sizes = [2, 3, 4, 5, 6]\n",
    "num_epochs = 5\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_params = {}\n",
    "\n",
    "results = {}  # Dictionary to store results\n",
    "\n",
    "# Counter to keep track of configurations\n",
    "config_count = 1\n",
    "total_configs = (\n",
    "    len(learning_rates)\n",
    "    * len(batch_sizes)\n",
    "    * len(optimizers)\n",
    "    * len(dropout_rates)\n",
    "    * len(kernel_sizes)\n",
    ")\n",
    "# Grid search\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for opt in optimizers:\n",
    "            for dr in dropout_rates:\n",
    "                for ks in kernel_sizes:\n",
    "                    config_key = f\"LR: {lr}, BS: {bs}, Optimizer: {opt.__name__}, Dropout: {dr}, Kernel: {ks}\"\n",
    "                    print(f\"Configuration {config_count}/{total_configs}:\")\n",
    "                    print(config_key)\n",
    "\n",
    "                    train_loader = torch.utils.data.DataLoader(train_set, batch_size=bs)\n",
    "                    test_loader = torch.utils.data.DataLoader(test_set, batch_size=bs)\n",
    "\n",
    "                    model = AdjustedFashionCNN(kernel_size=ks, dropout_rate=dr).to(\n",
    "                        device\n",
    "                    )\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "                    optimizer = opt(model.parameters(), lr=lr)\n",
    "\n",
    "                    # Variables to store cumulative loss across epochs\n",
    "                    total_train_loss = 0.0\n",
    "                    total_test_loss = 0.0\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    # Train and test the model with the current hyperparameters for the specified number of epochs\n",
    "                    for epoch in range(num_epochs):\n",
    "                        train_accuracy, train_loss = train(\n",
    "                            model, train_loader, criterion, optimizer\n",
    "                        )\n",
    "                        total_train_loss += train_loss\n",
    "\n",
    "                        # Skip further training and testing for this configuration if training accuracy is less than 80%\n",
    "                        if train_accuracy < 80.0:\n",
    "                            print(\n",
    "                                \"Train accuracy is less than 80%. Skipping this configuration.\"\n",
    "                            )\n",
    "                            break\n",
    "\n",
    "                        test_accuracy, test_loss = test(model, test_loader)\n",
    "                        total_test_loss += test_loss\n",
    "\n",
    "                        # Printing per-epoch results\n",
    "                        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "                        print(\n",
    "                            f\"Train Accuracy: {train_accuracy:.2f}% - Train Loss: {train_loss:.4f}\"\n",
    "                        )\n",
    "                        print(\n",
    "                            f\"Test Accuracy: {test_accuracy:.2f}% - Test Loss: {test_loss:.4f}\"\n",
    "                        )\n",
    "                        print(\"----------------------------------------\")\n",
    "\n",
    "                    avg_train_loss = total_train_loss / num_epochs\n",
    "                    avg_test_loss = total_test_loss / num_epochs\n",
    "                    end_time = time.time()\n",
    "                    config_time = end_time - start_time\n",
    "\n",
    "                    # Store the results ONLY if train_accuracy >= 80%\n",
    "                    if train_accuracy >= 80.0:\n",
    "                        results[config_key] = {\n",
    "                            \"Train Accuracy\": train_accuracy,\n",
    "                            \"Test Accuracy\": test_accuracy,\n",
    "                            \"Average Train Loss\": avg_train_loss,\n",
    "                            \"Average Test Loss\": avg_test_loss,\n",
    "                            \"Time (in sec)\": config_time,\n",
    "                        }\n",
    "\n",
    "                    # Update best accuracy and parameters\n",
    "                    if test_accuracy > best_accuracy:\n",
    "                        best_accuracy = test_accuracy\n",
    "                        best_params = {\n",
    "                            \"lr\": lr,\n",
    "                            \"batch_size\": bs,\n",
    "                            \"optimizer\": opt,\n",
    "                            \"dropout_rate\": dr,\n",
    "                            \"kernel_size\": ks,\n",
    "                        }\n",
    "                    print(\"------------------------------------------------------\")\n",
    "                    config_count += 1\n",
    "\n",
    "print(\"Best Test Accuracy:\", best_accuracy)\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'results.csv'\n"
     ]
    }
   ],
   "source": [
    "# Convert the results dictionary to a DataFrame\n",
    "df_results = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_results.to_csv(\"./data/results.csv\")\n",
    "\n",
    "print(\"Results saved to 'results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run their parameters in the fashion and get the results -- 97.2%\n",
    "# run the different parameters in the fashion data and get the best combinations .... Arend claimed low Kernel size will be better\n",
    "# take the best hyperparameter and run it on the MRI data set and then compare\n",
    "# check if hyper-tuning on small dataset can be faster/better/works and if our claim would be correct and generalize it to larger dataset\n",
    "# then check if we get better results than the MRI paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters to tune\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "optimizers = [torch.optim.SGD, torch.optim.Adam]\n",
    "dropout_rates = [0.2, 0.5]\n",
    "kernel_sizes = [2, 3, 4, 5, 6]\n",
    "num_epochs = 30\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_params = {}\n",
    "\n",
    "results = {}  # Dictionary to store results\n",
    "\n",
    "# Counter to keep track of configurations\n",
    "config_count = 1\n",
    "total_configs = (\n",
    "    len(learning_rates)\n",
    "    * len(batch_sizes)\n",
    "    * len(optimizers)\n",
    "    * len(dropout_rates)\n",
    "    * len(kernel_sizes)\n",
    ")\n",
    "# Grid search\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for opt in optimizers:\n",
    "            for dr in dropout_rates:\n",
    "                for ks in kernel_sizes:\n",
    "                    config_key = f\"LR: {lr}, BS: {bs}, Optimizer: {opt.__name__}, Dropout: {dr}, Kernel: {ks}\"\n",
    "                    print(f\"Configuration {config_count}/{total_configs}:\")\n",
    "                    print(config_key)\n",
    "\n",
    "                    train_loader = torch.utils.data.DataLoader(train_set, batch_size=bs)\n",
    "                    test_loader = torch.utils.data.DataLoader(test_set, batch_size=bs)\n",
    "\n",
    "                    model = AdjustedFashionCNN(kernel_size=ks, dropout_rate=dr).to(\n",
    "                        device\n",
    "                    )\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "                    optimizer = opt(model.parameters(), lr=lr)\n",
    "\n",
    "                    # Variables to store cumulative loss across epochs\n",
    "                    total_train_loss = 0.0\n",
    "                    total_test_loss = 0.0\n",
    "\n",
    "                    # Train and test the model with the current hyperparameters for the specified number of epochs\n",
    "                    for epoch in range(num_epochs):\n",
    "                        train_accuracy, train_loss = train(\n",
    "                            model, train_loader, criterion, optimizer\n",
    "                        )\n",
    "                        total_train_loss += train_loss\n",
    "\n",
    "                        # Skip further training and testing for this configuration if training accuracy is less than 80%\n",
    "                        if train_accuracy < 80.0:\n",
    "                            print(\n",
    "                                \"Train accuracy is less than 80%. Skipping this configuration.\"\n",
    "                            )\n",
    "                            break\n",
    "\n",
    "                        test_accuracy, test_loss = test(model, test_loader)\n",
    "                        total_test_loss += test_loss\n",
    "\n",
    "                        # Printing per-epoch results\n",
    "                        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "                        print(\n",
    "                            f\"Train Accuracy: {train_accuracy:.2f}% - Train Loss: {train_loss:.4f}\"\n",
    "                        )\n",
    "                        print(\n",
    "                            f\"Test Accuracy: {test_accuracy:.2f}% - Test Loss: {test_loss:.4f}\"\n",
    "                        )\n",
    "                        print(\"----------------------------------------\")\n",
    "\n",
    "                    avg_train_loss = total_train_loss / num_epochs\n",
    "                    avg_test_loss = total_test_loss / num_epochs\n",
    "\n",
    "                    # Store the results ONLY if train_accuracy >= 80%\n",
    "                    if train_accuracy >= 80.0:\n",
    "                        results[config_key] = {\n",
    "                            \"Train Accuracy\": train_accuracy,\n",
    "                            \"Test Accuracy\": test_accuracy,\n",
    "                            \"Average Train Loss\": avg_train_loss,\n",
    "                            \"Average Test Loss\": avg_test_loss,\n",
    "                        }\n",
    "\n",
    "                    # Update best accuracy and parameters\n",
    "                    if test_accuracy > best_accuracy:\n",
    "                        best_accuracy = test_accuracy\n",
    "                        best_params = {\n",
    "                            \"lr\": lr,\n",
    "                            \"batch_size\": bs,\n",
    "                            \"optimizer\": opt,\n",
    "                            \"dropout_rate\": dr,\n",
    "                            \"kernel_size\": ks,\n",
    "                        }\n",
    "                    print(\"------------------------------------------------------\")\n",
    "                    config_count += 1\n",
    "\n",
    "print(\"Best Test Accuracy:\", best_accuracy)\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
